{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>avg_line_length</th>\n",
       "      <th>max_line_length</th>\n",
       "      <th>alphanum_fraction</th>\n",
       "      <th>licenses</th>\n",
       "      <th>repository_name</th>\n",
       "      <th>path</th>\n",
       "      <th>size</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td># Copyright 2020 gRPC authors.\\n#\\n# Licensed ...</td>\n",
       "      <td>34.215686</td>\n",
       "      <td>78</td>\n",
       "      <td>0.731805</td>\n",
       "      <td>[Apache-2.0]</td>\n",
       "      <td>1261385937/grpc</td>\n",
       "      <td>examples/python/helloworld/async_greeter_serve...</td>\n",
       "      <td>1745</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>import scipy.sparse as sp\\nimport numpy as np\\...</td>\n",
       "      <td>47.351351</td>\n",
       "      <td>192</td>\n",
       "      <td>0.574543</td>\n",
       "      <td>[Apache-2.0]</td>\n",
       "      <td>jiangnanboy/gcn_for_prediction_of_protein_inte...</td>\n",
       "      <td>src/graph_nheads_att_gan/train.py</td>\n",
       "      <td>9490</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td># Copyright 2019 The TensorFlow Authors. All R...</td>\n",
       "      <td>37.452128</td>\n",
       "      <td>84</td>\n",
       "      <td>0.569805</td>\n",
       "      <td>[Apache-2.0]</td>\n",
       "      <td>aryaman4/tensorboard</td>\n",
       "      <td>tensorboard/plugins/hparams/backend_context_te...</td>\n",
       "      <td>14082</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#!/usr/bin/env python2\\n# Copyright (c) 2014-2...</td>\n",
       "      <td>40.438017</td>\n",
       "      <td>214</td>\n",
       "      <td>0.556019</td>\n",
       "      <td>[MIT]</td>\n",
       "      <td>alik918/esmacoin</td>\n",
       "      <td>qa/rpc-tests/fundrawtransaction.py</td>\n",
       "      <td>24465</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td># Copyright (c) 2017, John Skinner\\nimport uni...</td>\n",
       "      <td>38.830769</td>\n",
       "      <td>98</td>\n",
       "      <td>0.682448</td>\n",
       "      <td>[BSD-2-Clause]</td>\n",
       "      <td>jskinn/arvet</td>\n",
       "      <td>arvet/batch_analysis/tests/test_task.py</td>\n",
       "      <td>10096</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  avg_line_length  \\\n",
       "0  # Copyright 2020 gRPC authors.\\n#\\n# Licensed ...        34.215686   \n",
       "1  import scipy.sparse as sp\\nimport numpy as np\\...        47.351351   \n",
       "2  # Copyright 2019 The TensorFlow Authors. All R...        37.452128   \n",
       "3  #!/usr/bin/env python2\\n# Copyright (c) 2014-2...        40.438017   \n",
       "4  # Copyright (c) 2017, John Skinner\\nimport uni...        38.830769   \n",
       "\n",
       "   max_line_length  alphanum_fraction        licenses  \\\n",
       "0               78           0.731805    [Apache-2.0]   \n",
       "1              192           0.574543    [Apache-2.0]   \n",
       "2               84           0.569805    [Apache-2.0]   \n",
       "3              214           0.556019           [MIT]   \n",
       "4               98           0.682448  [BSD-2-Clause]   \n",
       "\n",
       "                                     repository_name  \\\n",
       "0                                    1261385937/grpc   \n",
       "1  jiangnanboy/gcn_for_prediction_of_protein_inte...   \n",
       "2                               aryaman4/tensorboard   \n",
       "3                                   alik918/esmacoin   \n",
       "4                                       jskinn/arvet   \n",
       "\n",
       "                                                path   size    lang  \n",
       "0  examples/python/helloworld/async_greeter_serve...   1745  Python  \n",
       "1                  src/graph_nheads_att_gan/train.py   9490  Python  \n",
       "2  tensorboard/plugins/hparams/backend_context_te...  14082  Python  \n",
       "3                 qa/rpc-tests/fundrawtransaction.py  24465  Python  \n",
       "4            arvet/batch_analysis/tests/test_task.py  10096  Python  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "python_df = pd.read_parquet(\"hf://datasets/ml6team/the-stack-smol-python/data/train-00000-of-00001-7b3873c38afd2d66.parquet\")\n",
    "\n",
    "python_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import scipy.sparse as sp\n",
      "import numpy as np\n",
      "import torch\n",
      "import time\n",
      "import os\n",
      "from configparser import ConfigParser\n",
      "\n",
      "import sys\n",
      "sys.path.append('/home/shiyan/project/gcn_for_prediction_of_protein_interactions/')\n",
      "\n",
      "from src.util.load_data import load_data, sparse_to_tuple, mask_test_edges, preprocess_graph\n",
      "from src.util.loss import arga_loss_function, varga_loss_function\n",
      "from src.util.metrics import get_roc_score\n",
      "from src.util import define_optimizer\n",
      "from src.graph_nheads_att_gan.model import NHGATModelGAN\n",
      "\n",
      "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
      "\n",
      "class Train():\n",
      "    def __init__(self):\n",
      "        pass\n",
      "\n",
      "    def train_model(self, config_path):\n",
      "        if os.path.exists(config_path) and (os.path.split(config_path)[1].split('.')[0] == 'config') and (\n",
      "                os.path.splitext(config_path)[1].split('.')[1] == 'cfg'):\n",
      "            # load config file\n",
      "            config = ConfigParser()\n",
      "            config.read(config_path)\n",
      "            section = config.sections()[0]\n",
      "\n",
      "            # data catalog path\n",
      "            data_catalog = config.get(section, \"data_catalog\")\n",
      "\n",
      "            # train file path\n",
      "            train_file_name = config.get(section, \"train_file_name\")\n",
      "\n",
      "            # model save/load path\n",
      "            model_path = config.get(section, \"model_path\")\n",
      "\n",
      "            # model param config\n",
      "            hidden_dim1 = config.getint(section, \"hidden_dim1\")\n",
      "            hidden_dim2 = config.getint(section, \"hidden_dim2\")\n",
      "            hidden_dim3 = config.getint(section, 'hidden_dim3')\n",
      "            num_heads = config.getint(section, 'num_heads')\n",
      "            dropout = config.getfloat(section, \"dropout\")\n",
      "            vae_bool = config.getboolean(section, 'vae_bool')\n",
      "            alpha = config.getfloat(section, 'alpha')\n",
      "            lr = config.getfloat(section, \"lr\")\n",
      "            lr_decay = config.getfloat(section, 'lr_decay')\n",
      "            weight_decay = config.getfloat(section, \"weight_decay\")\n",
      "            gamma = config.getfloat(section, \"gamma\")\n",
      "            momentum = config.getfloat(section, \"momentum\")\n",
      "            eps = config.getfloat(section, \"eps\")\n",
      "            clip = config.getfloat(section, \"clip\")\n",
      "            epochs = config.getint(section, \"epochs\")\n",
      "            optimizer_name = config.get(section, \"optimizer\")\n",
      "\n",
      "            # 加载相关数据\n",
      "            adj = load_data(os.path.join(data_catalog, train_file_name))\n",
      "            num_nodes = adj.shape[0]\n",
      "            num_edges = adj.sum()\n",
      "\n",
      "            features = sparse_to_tuple(sp.identity(num_nodes))\n",
      "            num_features = features[2][1]\n",
      "\n",
      "            # 去除对角线元素\n",
      "            # 下边的右部分为：返回adj_orig的对角元素（一维），并增加一维，抽出adj_orig的对角元素并构建只有这些对角元素的对角矩阵\n",
      "            adj_orig = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
      "            adj_orig.eliminate_zeros()\n",
      "\n",
      "            adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj_orig)\n",
      "\n",
      "            adj = adj_train\n",
      "\n",
      "            # 返回D^{-0.5}SD^{-0.5}的coords, data, shape，其中S=A+I\n",
      "            adj_norm = preprocess_graph(adj)\n",
      "            adj_label = adj_train + sp.eye(adj_train.shape[0])\n",
      "            # adj_label = sparse_to_tuple(adj_label)\n",
      "            adj_label = torch.FloatTensor(adj_label.toarray()).to(DEVICE)\n",
      "            '''\n",
      "            注意，adj的每个元素非1即0。pos_weight是用于训练的邻接矩阵中负样本边（既不存在的边）和正样本边的倍数（即比值），这个数值在二分类交叉熵损失函数中用到，\n",
      "            如果正样本边所占的比例和负样本边所占比例失衡，比如正样本边很多，负样本边很少，那么在求loss的时候可以提供weight参数，将正样本边的weight设置小一点，负样本边的weight设置大一点，\n",
      "            此时能够很好的平衡两类在loss中的占比，任务效果可以得到进一步提升。参考：https://www.zhihu.com/question/383567632\n",
      "            负样本边的weight都为1，正样本边的weight都为pos_weight\n",
      "            '''\n",
      "            pos_weight = float(adj.shape[0] * adj.shape[0] - num_edges) / num_edges\n",
      "            norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
      "\n",
      "            # create model\n",
      "            print('create model ...')\n",
      "            model = NHGATModelGAN(num_features, hidden_dim1=hidden_dim1, hidden_dim2=hidden_dim2, hidden_dim3=hidden_dim3, num_heads=num_heads, dropout=dropout, alpha=alpha, vae_bool=vae_bool)\n",
      "\n",
      "            # define optimizer\n",
      "            if optimizer_name == 'adam':\n",
      "                optimizer = define_optimizer.define_optimizer_adam(model, lr=lr, weight_decay=weight_decay)\n",
      "\n",
      "            elif optimizer_name == 'adamw':\n",
      "                optimizer = define_optimizer.define_optimizer_adamw(model, lr=lr, weight_decay=weight_decay)\n",
      "\n",
      "            elif optimizer_name == 'sgd':\n",
      "                optimizer = define_optimizer.define_optimizer_sgd(model, lr=lr, momentum=momentum,\n",
      "                                                                  weight_decay=weight_decay)\n",
      "\n",
      "            elif optimizer_name == 'adagrad':\n",
      "                optimizer = define_optimizer.define_optimizer_adagrad(model, lr=lr, lr_decay=lr_decay,\n",
      "                                                                      weight_decay=weight_decay)\n",
      "\n",
      "            elif optimizer_name == 'rmsprop':\n",
      "                optimizer = define_optimizer.define_optimizer_rmsprop(model, lr=lr, weight_decay=weight_decay,\n",
      "                                                                      momentum=momentum)\n",
      "\n",
      "            elif optimizer_name == 'adadelta':\n",
      "                optimizer = define_optimizer.define_optimizer_adadelta(model, lr=lr, weight_decay=weight_decay)\n",
      "\n",
      "            else:\n",
      "                raise NameError('No define optimization function name!')\n",
      "\n",
      "            model = model.to(DEVICE)\n",
      "            # 稀疏张量被表示为一对致密张量：一维张量和二维张量的索引。可以通过提供这两个张量来构造稀疏张量\n",
      "            adj_norm = torch.sparse.FloatTensor(torch.LongTensor(adj_norm[0].T),\n",
      "                                                torch.FloatTensor(adj_norm[1]),\n",
      "                                                torch.Size(adj_norm[2]))\n",
      "            features = torch.sparse.FloatTensor(torch.LongTensor(features[0].T),\n",
      "                                                torch.FloatTensor(features[1]),\n",
      "                                                torch.Size(features[2])).to_dense()\n",
      "            adj_norm = adj_norm.to(DEVICE)\n",
      "            features = features.to(DEVICE)\n",
      "            norm = torch.FloatTensor(np.array(norm)).to(DEVICE)\n",
      "            pos_weight = torch.tensor(pos_weight).to(DEVICE)\n",
      "            num_nodes = torch.tensor(num_nodes).to(DEVICE)\n",
      "\n",
      "            print('start training...')\n",
      "            best_valid_roc_score = float('-inf')\n",
      "            hidden_emb = None\n",
      "            model.train()\n",
      "            for epoch in range(epochs):\n",
      "                t = time.time()\n",
      "                optimizer.zero_grad()\n",
      "                # 解码后的邻接矩阵，判别器\n",
      "                recovered, dis_real, dis_fake, mu, logvar = model(features, adj_norm)\n",
      "                if vae_bool:\n",
      "                    loss = varga_loss_function(preds=recovered, labels=adj_label,\n",
      "                                               mu=mu, logvar=logvar,\n",
      "                                               dis_real=dis_real, dis_fake=dis_fake,\n",
      "                                               n_nodes=num_nodes,\n",
      "                                               norm=norm, pos_weight=pos_weight)\n",
      "                else:\n",
      "                    loss = arga_loss_function(preds=recovered, labels=adj_label,\n",
      "                                              dis_real=dis_real, dis_fake=dis_fake,\n",
      "                                              norm=norm, pos_weight=pos_weight)\n",
      "                loss.backward()\n",
      "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
      "                cur_loss = loss.item()\n",
      "                optimizer.step()\n",
      "\n",
      "                hidden_emb = mu.data.cpu().numpy()\n",
      "                # 评估验证集，val set\n",
      "                roc_score, ap_score = get_roc_score(hidden_emb, adj_orig, val_edges, val_edges_false)\n",
      "                # 保存最好的roc score\n",
      "                if roc_score > best_valid_roc_score:\n",
      "                    best_valid_roc_score = roc_score\n",
      "                    # 不需要保存整个model，只需保存hidden_emb，因为后面的解码是用hidden_emb内积的形式作推断\n",
      "                    np.save(model_path, hidden_emb)\n",
      "\n",
      "                print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss = \", \"{:.5f}\".format(cur_loss),\n",
      "                      \"val_roc_score = \", \"{:.5f}\".format(roc_score),\n",
      "                      \"average_precision_score = \", \"{:.5f}\".format(ap_score),\n",
      "                      \"time=\", \"{:.5f}\".format(time.time() - t)\n",
      "                      )\n",
      "\n",
      "            print(\"Optimization Finished!\")\n",
      "\n",
      "            # 评估测试集，test set\n",
      "            roc_score, ap_score = get_roc_score(hidden_emb, adj_orig, test_edges, test_edges_false)\n",
      "            print('test roc score: {}'.format(roc_score))\n",
      "            print('test ap score: {}'.format(ap_score))\n",
      "\n",
      "        else:\n",
      "            raise FileNotFoundError('File config.cfg not found : ' + config_path)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    config_path = os.path.join(os.getcwd(), 'config.cfg')\n",
      "    train = Train()\n",
      "    train.train_model(config_path)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print content of first row\n",
    "print(python_df.iloc[1]['content'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
